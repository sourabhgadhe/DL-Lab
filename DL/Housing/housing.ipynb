{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression by using Deep Neural network: \n",
    "Implement Boston housing price prediction problem by Linear regression using Deep Neural network. \n",
    "Use Boston House price prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('housing.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing null values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM        True\n",
       "ZN          True\n",
       "INDUS       True\n",
       "CHAS        True\n",
       "NOX        False\n",
       "RM         False\n",
       "AGE         True\n",
       "DIS        False\n",
       "RAD        False\n",
       "TAX        False\n",
       "PTRATIO    False\n",
       "B          False\n",
       "LSTAT       True\n",
       "MEDV       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_null = df.columns[df.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CRIM', 'ZN', 'INDUS', 'CHAS', 'AGE', 'LSTAT']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       False\n",
       "ZN         False\n",
       "INDUS      False\n",
       "CHAS       False\n",
       "NOX        False\n",
       "RM         False\n",
       "AGE        False\n",
       "DIS        False\n",
       "RAD        False\n",
       "TAX        False\n",
       "PTRATIO    False\n",
       "B          False\n",
       "LSTAT      False\n",
       "MEDV       False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in columns_with_null:\n",
    "    column_mean = df[column].mean()\n",
    "    df[column].fillna(column_mean, inplace=True)\n",
    "\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y= df.MEDV\n",
    "# Split the data into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128,activation = 'relu',input_dim =13))\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(32,activation = 'relu'))\n",
    "model.add(Dense(16,activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer = 'adam',loss ='mean_squared_error',metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 2s 27ms/step - loss: 593.4413 - mae: 22.5142 - val_loss: 560.9605 - val_mae: 22.2034\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 536.9495 - mae: 21.3165 - val_loss: 479.1248 - val_mae: 20.4403\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 421.1335 - mae: 18.6566 - val_loss: 322.8085 - val_mae: 16.5305\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 236.0869 - mae: 13.0976 - val_loss: 101.0277 - val_mae: 8.4573\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 88.1116 - mae: 7.4569 - val_loss: 49.5790 - val_mae: 5.0605\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 56.7947 - mae: 5.7787 - val_loss: 33.8268 - val_mae: 3.8487\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 36.4316 - mae: 4.5673 - val_loss: 34.4977 - val_mae: 4.0543\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 25.7545 - mae: 3.7083 - val_loss: 32.9716 - val_mae: 3.8388\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 23.8238 - mae: 3.6288 - val_loss: 33.5938 - val_mae: 3.9221\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 20.8690 - mae: 3.2738 - val_loss: 32.8742 - val_mae: 3.9136\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 19.2150 - mae: 3.1580 - val_loss: 31.3731 - val_mae: 3.6565\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 18.0516 - mae: 3.0677 - val_loss: 29.3408 - val_mae: 3.5502\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 16.8421 - mae: 2.9386 - val_loss: 28.9400 - val_mae: 3.5498\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 16.0418 - mae: 2.8709 - val_loss: 30.7061 - val_mae: 3.6073\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15.3011 - mae: 2.8437 - val_loss: 27.8857 - val_mae: 3.4733\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 14.7043 - mae: 2.7504 - val_loss: 26.9053 - val_mae: 3.4676\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 14.1232 - mae: 2.7084 - val_loss: 27.0549 - val_mae: 3.4759\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 13.7359 - mae: 2.6548 - val_loss: 27.4572 - val_mae: 3.5415\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 13.2783 - mae: 2.6090 - val_loss: 25.8446 - val_mae: 3.4245\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 12.8986 - mae: 2.5923 - val_loss: 26.3535 - val_mae: 3.4732\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12.7668 - mae: 2.5377 - val_loss: 25.6155 - val_mae: 3.4132\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12.4021 - mae: 2.5498 - val_loss: 25.3727 - val_mae: 3.4361\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 12.1860 - mae: 2.4904 - val_loss: 24.9128 - val_mae: 3.4043\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11.8232 - mae: 2.4898 - val_loss: 25.2593 - val_mae: 3.4070\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.4696 - mae: 2.4336 - val_loss: 24.8576 - val_mae: 3.4173\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.3325 - mae: 2.4147 - val_loss: 24.6616 - val_mae: 3.4066\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.1145 - mae: 2.4004 - val_loss: 24.1241 - val_mae: 3.3943\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 11.2695 - mae: 2.4190 - val_loss: 22.2826 - val_mae: 3.1971\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.8998 - mae: 2.3968 - val_loss: 24.0626 - val_mae: 3.3749\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.6349 - mae: 2.3262 - val_loss: 23.0319 - val_mae: 3.3160\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.3683 - mae: 2.3108 - val_loss: 23.2935 - val_mae: 3.3458\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 10.2978 - mae: 2.3368 - val_loss: 23.1877 - val_mae: 3.3277\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.0357 - mae: 2.2708 - val_loss: 22.6241 - val_mae: 3.2927\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 10.0367 - mae: 2.2886 - val_loss: 22.8320 - val_mae: 3.2750\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 9.9562 - mae: 2.2864 - val_loss: 22.8076 - val_mae: 3.3323\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.8011 - mae: 2.2453 - val_loss: 21.5909 - val_mae: 3.2482\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.7950 - mae: 2.2695 - val_loss: 21.9434 - val_mae: 3.2959\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.4027 - mae: 2.2382 - val_loss: 22.2231 - val_mae: 3.3487\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.3362 - mae: 2.2207 - val_loss: 20.7556 - val_mae: 3.1794\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 9.2971 - mae: 2.2352 - val_loss: 22.0620 - val_mae: 3.3359\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.8866 - mae: 2.1788 - val_loss: 20.5897 - val_mae: 3.2247\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.0494 - mae: 2.1991 - val_loss: 21.5904 - val_mae: 3.2781\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.8062 - mae: 2.2234 - val_loss: 21.4078 - val_mae: 3.2789\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.9855 - mae: 2.1849 - val_loss: 22.7820 - val_mae: 3.3899\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.6386 - mae: 2.1871 - val_loss: 20.3284 - val_mae: 3.2174\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.4492 - mae: 2.1301 - val_loss: 21.4993 - val_mae: 3.3030\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.2884 - mae: 2.1182 - val_loss: 20.9297 - val_mae: 3.2782\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 8.2335 - mae: 2.1249 - val_loss: 21.6044 - val_mae: 3.3246\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 8.0705 - mae: 2.0817 - val_loss: 20.7989 - val_mae: 3.2748\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.9977 - mae: 2.0780 - val_loss: 20.9371 - val_mae: 3.2975\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.0312 - mae: 2.1024 - val_loss: 20.7863 - val_mae: 3.3101\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.1493 - mae: 2.1403 - val_loss: 21.2282 - val_mae: 3.3517\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 7.9273 - mae: 2.0740 - val_loss: 20.9749 - val_mae: 3.3079\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.1732 - mae: 2.1445 - val_loss: 21.1325 - val_mae: 3.3155\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.6426 - mae: 2.0223 - val_loss: 19.5054 - val_mae: 3.2119\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.7364 - mae: 2.0941 - val_loss: 20.9046 - val_mae: 3.3743\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.2396 - mae: 1.9977 - val_loss: 20.7439 - val_mae: 3.3656\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.4069 - mae: 2.0230 - val_loss: 19.6297 - val_mae: 3.2514\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 7.2927 - mae: 1.9944 - val_loss: 20.2583 - val_mae: 3.2815\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 7.2869 - mae: 1.9778 - val_loss: 21.1627 - val_mae: 3.3933\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.3092 - mae: 2.0815 - val_loss: 19.8504 - val_mae: 3.2745\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.9261 - mae: 1.9435 - val_loss: 19.8699 - val_mae: 3.2978\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 6.8512 - mae: 1.9927 - val_loss: 19.1260 - val_mae: 3.2371\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.7620 - mae: 1.9304 - val_loss: 20.5529 - val_mae: 3.3742\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.6227 - mae: 1.9073 - val_loss: 20.1773 - val_mae: 3.3490\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5251 - mae: 1.9255 - val_loss: 19.3053 - val_mae: 3.2705\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.6401 - mae: 1.9159 - val_loss: 19.5092 - val_mae: 3.2605\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.5255 - mae: 1.9106 - val_loss: 19.8238 - val_mae: 3.2999\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 6.3082 - mae: 1.8864 - val_loss: 18.8879 - val_mae: 3.2289\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 6.1339 - mae: 1.8483 - val_loss: 19.7375 - val_mae: 3.3181\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 6.0954 - mae: 1.8372 - val_loss: 19.2536 - val_mae: 3.2955\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.9734 - mae: 1.8176 - val_loss: 19.7873 - val_mae: 3.3455\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.9292 - mae: 1.8142 - val_loss: 17.6622 - val_mae: 3.1407\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.8770 - mae: 1.8021 - val_loss: 18.8547 - val_mae: 3.2657\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.8318 - mae: 1.7753 - val_loss: 19.2710 - val_mae: 3.2829\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.6462 - mae: 1.7583 - val_loss: 18.5283 - val_mae: 3.2295\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.6055 - mae: 1.7642 - val_loss: 19.1807 - val_mae: 3.2949\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.5231 - mae: 1.7457 - val_loss: 19.0622 - val_mae: 3.3006\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.3958 - mae: 1.7284 - val_loss: 18.9128 - val_mae: 3.2845\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 5.4538 - mae: 1.7623 - val_loss: 18.7484 - val_mae: 3.2799\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.4987 - mae: 1.7703 - val_loss: 18.8525 - val_mae: 3.3003\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.3192 - mae: 1.6982 - val_loss: 18.6461 - val_mae: 3.2553\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.2425 - mae: 1.7000 - val_loss: 17.3948 - val_mae: 3.1489\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.1628 - mae: 1.6797 - val_loss: 18.9121 - val_mae: 3.2691\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 5.0485 - mae: 1.6795 - val_loss: 18.6371 - val_mae: 3.2760\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 5.1177 - mae: 1.6833 - val_loss: 18.0330 - val_mae: 3.1867\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.1016 - mae: 1.6756 - val_loss: 19.3946 - val_mae: 3.2961\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 4.9815 - mae: 1.6510 - val_loss: 18.2813 - val_mae: 3.2170\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.9431 - mae: 1.6624 - val_loss: 17.6335 - val_mae: 3.1614\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 5.1219 - mae: 1.6791 - val_loss: 18.2082 - val_mae: 3.2508\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.9486 - mae: 1.6593 - val_loss: 18.3606 - val_mae: 3.2001\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 4.7532 - mae: 1.6158 - val_loss: 18.4163 - val_mae: 3.2197\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.7760 - mae: 1.6247 - val_loss: 17.6170 - val_mae: 3.1530\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 4.5458 - mae: 1.6008 - val_loss: 17.1539 - val_mae: 3.1290\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.4787 - mae: 1.5627 - val_loss: 17.2273 - val_mae: 3.1170\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.3760 - mae: 1.5462 - val_loss: 18.1575 - val_mae: 3.2000\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.5601 - mae: 1.5627 - val_loss: 17.3588 - val_mae: 3.1288\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.3941 - mae: 1.5648 - val_loss: 17.1949 - val_mae: 3.1340\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 4.3812 - mae: 1.5419 - val_loss: 16.6416 - val_mae: 3.0536\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 4.2119 - mae: 1.5321 - val_loss: 17.4244 - val_mae: 3.1554\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 12.3665 - mae: 2.2713\n",
      "Root Mean squared error on test data:  3.516596409847655\n",
      "Mean absolute error on test data:  2.2713260650634766\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "y_pred = model.predict(X_test)\n",
    "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
    "print('Root Mean squared error on test data: ', math.sqrt(mse_nn))\n",
    "print('Mean absolute error on test data: ', mae_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter CRIM value: 0.03237\n",
      "Enter ZN value: 0\n",
      "Enter INDUS value: 2.18\n",
      "Enter CHAS value: 0\n",
      "Enter NOX value: 0.45\n",
      "Enter RM value: 7\n",
      "Enter AGE value: 45.80\n",
      "Enter DIS value: 6\n",
      "Enter RAD value: 3\n",
      "Enter TAX value: 222\n",
      "Enter PTRATIO value: 18.70\n",
      "Enter B value: 394.63\n",
      "Enter LSTAT value: 2.94\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "The predicted MEDV value is: 31.61345100402832\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def predict_MEDV(model, input_data):\n",
    "    \n",
    "    input_array = np.array([list(input_data.values())])\n",
    "    input_array = sc.transform(input_array)   # most imp\n",
    "    predictions = model.predict(input_array)\n",
    "    return (predictions[0][0])\n",
    "\n",
    "\n",
    "input_data = {\n",
    "    'CRIM' : float(input(\"Enter CRIM value: \")),\n",
    "    'ZN' : float(input(\"Enter ZN value: \")),\n",
    "    'INDUS' : float(input(\"Enter INDUS value: \")),\n",
    "    'CHAS' : float(input(\"Enter CHAS value: \")),\n",
    "    'NOX' : float(input(\"Enter NOX value: \")),\n",
    "    'RM' : float(input(\"Enter RM value: \")),\n",
    "    'AGE' : float(input(\"Enter AGE value: \")),\n",
    "    'DIS' : float(input(\"Enter DIS value: \")),\n",
    "    'RAD': float(input(\"Enter RAD value: \")),\n",
    "    'TAX' : float(input(\"Enter TAX value: \")),\n",
    "    'PTRATIO': float(input(\"Enter PTRATIO value: \")),\n",
    "    'B' : float(input(\"Enter B value: \")),\n",
    "    'LSTAT' : float(input(\"Enter LSTAT value: \"))\n",
    "}\n",
    "\n",
    "predicted_MEDV = predict_MEDV(model, input_data)\n",
    "\n",
    "print(f'The predicted MEDV value is: {predicted_MEDV}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM         0.03237\n",
       "ZN           0.00000\n",
       "INDUS        2.18000\n",
       "CHAS         0.00000\n",
       "NOX          0.45800\n",
       "RM           6.99800\n",
       "AGE         45.80000\n",
       "DIS          6.06220\n",
       "RAD          3.00000\n",
       "TAX        222.00000\n",
       "PTRATIO     18.70000\n",
       "B          394.63000\n",
       "LSTAT        2.94000\n",
       "MEDV        33.40000\n",
       "Name: 3, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
