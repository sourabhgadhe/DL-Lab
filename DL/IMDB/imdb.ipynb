{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification using Deep neural network:\n",
    "Binary classification using Deep Neural Networks Example: Classify movie reviews into \n",
    "positive reviews and negative reviews, just based on the text content of the reviews.\n",
    "Use IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the IMDB dataset with the top 10,000 most frequently occurring words\n",
    "\n",
    "max_words = 10000\n",
    "(x_train,y_train), (x_test,y_test) = imdb.load_data(num_words = max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data: pad sequences to have the same length\n",
    "\n",
    "max_len = 200\n",
    "x_train = pad_sequences(x_train,max_len)\n",
    "x_test = pad_sequences(x_test,max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=max_words, input_length = max_len, output_dim=32))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.4789 - accuracy: 0.7674 - val_loss: 0.3082 - val_accuracy: 0.8710\n",
      "Epoch 2/5\n",
      "625/625 [==============================] - 8s 13ms/step - loss: 0.2145 - accuracy: 0.9202 - val_loss: 0.2985 - val_accuracy: 0.8732\n",
      "Epoch 3/5\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.1148 - accuracy: 0.9676 - val_loss: 0.2915 - val_accuracy: 0.8806\n",
      "Epoch 4/5\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0526 - accuracy: 0.9912 - val_loss: 0.3241 - val_accuracy: 0.8718\n",
      "Epoch 5/5\n",
      "625/625 [==============================] - 7s 11ms/step - loss: 0.0236 - accuracy: 0.9981 - val_loss: 0.3500 - val_accuracy: 0.8734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28b7f7bfe50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 32)           320000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6401      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 326401 (1.25 MB)\n",
      "Trainable params: 326401 (1.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3610 - accuracy: 0.8700\n",
      "Loss: 0.3609621226787567\n",
      "Accuracy: 0.8700399994850159\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test,y_test)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Round predictions to convert probabilities to binary labels (0 or 1)\n",
    "binary_predictions = np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tActual\t\t\tPredicted\n",
      "\n",
      "0 \t\tNegative\t\tNegative\n",
      "1 \t\tPositive\t\tPositive\n",
      "2 \t\tPositive\t\tPositive\n",
      "3 \t\tNegative\t\tPositive\n",
      "4 \t\tPositive\t\tPositive\n",
      "5 \t\tPositive\t\tPositive\n",
      "6 \t\tPositive\t\tPositive\n",
      "7 \t\tNegative\t\tNegative\n",
      "8 \t\tNegative\t\tPositive\n",
      "9 \t\tPositive\t\tPositive\n",
      "10 \t\tPositive\t\tPositive\n",
      "11 \t\tNegative\t\tNegative\n",
      "12 \t\tNegative\t\tNegative\n",
      "13 \t\tNegative\t\tNegative\n",
      "14 \t\tPositive\t\tPositive\n",
      "15 \t\tNegative\t\tNegative\n",
      "16 \t\tPositive\t\tPositive\n",
      "17 \t\tNegative\t\tNegative\n",
      "18 \t\tNegative\t\tNegative\n",
      "19 \t\tNegative\t\tNegative\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\tActual\\t\\t\\tPredicted\")\n",
    "print()\n",
    "\n",
    "for i in range(20):\n",
    "    print(i,end=\" \\t\\t\")\n",
    "    actual = 'Positive' if y_test[i]==1 else 'Negative'\n",
    "    predicted = 'Positive' if binary_predictions[i]==1 else 'Negative'\n",
    "    print(f\"{actual}\\t\\t{predicted}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the index of the review: 15\n",
      "Review at index 15:\n",
      "\n",
      "was horrible the movie was utterly boring looked like the shadow with alec baldwin the shadow is infinitely better than this as well the character eve was so undeveloped and 2 dimensional she didn't even grab my attention i didn't even know her name was eve don was interesting when he kept his mouth shut the twist if you can call it that was laughable and pathetic when it came the movie had done such a horrid job of building suspense or ? to any character that i simply thought who gives a s the only thing that made me even lift an ? about this movie was the fact the ? teacher was ? in terminator 2 also a movie that was light years ahead of this motion picture massacre anyone who was involved in this movie should be ashamed of themselves for wasting 90 minutes of countless people's time it's no wonder no actor from this movie ever had a ? career in summary this movie is so bad i feel dirty and need a shower worst movie in history ? was better prom night the remake was better and dare i say it saw iv was better\n",
      "\n",
      "Actual Label: 0\n",
      "\n",
      "Predicted Label: [0.]\n"
     ]
    }
   ],
   "source": [
    "# Decode the integer sequences into sentences\n",
    "review_index = int(input(\"Enter the index of the review: \"))\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in x_test[review_index]])\n",
    "\n",
    "# Print the first review in the training set\n",
    "print(\"Review at index {}:\".format(review_index))\n",
    "print()\n",
    "print(decoded_review)\n",
    "\n",
    "# Print the corresponding label\n",
    "print(\"\\nActual Label:\", y_test[review_index])\n",
    "print(\"\\nPredicted Label:\", binary_predictions[review_index])\n",
    "#label  0 is -ve and label 1 is +ve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
